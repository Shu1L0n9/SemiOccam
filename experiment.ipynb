{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extracting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing normalization parameters based on loaded dataset\n",
      "100%|████████████████████████████████████████| 782/782 [00:04<00:00, 172.80it/s]\n",
      "Computed mean: [0.4913999140262604, 0.4821586608886719, 0.44653135538101196], std: [0.21117039024829865, 0.208579421043396, 0.2120516151189804]\n",
      "\n",
      "Dataset Information:\n",
      "Dataset: cifar10\n",
      "Train samples: 50000\n",
      "Test samples: 10000\n",
      "Classes: 10\n",
      "Image size: 518\n",
      "\n",
      "Loading model: vit_large_patch14_reg4_dinov2.lvd142m\n",
      "\n",
      "Extracting training features...\n",
      "Training:   100%|████████████████████████████████████████| 782/782 [00:00<3:23:08, 23.32s/it]\n"
     ]
    }
   ],
   "source": [
    "dataset_config = {\n",
    "    'dataset_type': 'cifar10',  # 'stl10', 'cifar10', 'cifar100'\n",
    "    'data_root': './data',      # Dataset root dictionary\n",
    "    'batch_size': 64,           # Batch size\n",
    "    'compute_norm': True        # Whether to compute the norm of the features\n",
    "}\n",
    "\n",
    "!python scripts/extract_features.py --dataset_type {dataset_config['dataset_type']} --data_root {dataset_config['data_root']} --batch_size {dataset_config['batch_size']} --compute_norm {dataset_config['compute_norm']}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGMM Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SGMM Training Configuration\n",
      "============================================================\n",
      "Dataset: cifar10\n",
      "Feature file: data/vit/cifar10/cifar10_vit_features.pt\n",
      "Labeled per class: 4\n",
      "PCA components: 60\n",
      "GMM components: 12\n",
      "Tolerance: 1.0\n",
      "Max iterations: 1024\n",
      "Device: cuda\n",
      "Random seed: 42\n",
      "============================================================\n",
      "Loading dataset...\n",
      "Loading dataset from: data/vit/cifar10/cifar10_vit_features.pt\n",
      "Dataset loaded successfully:\n",
      "  Training samples: 50000\n",
      "  Test samples: 10000\n",
      "\n",
      "Dataset split created:\n",
      "  Labeled samples: 40\n",
      "  Unlabeled samples: 49960\n",
      "  Classes: 10\n",
      "Labeled training data: (40, 1024)\n",
      "Unlabeled training data: (49960, 1024)\n",
      "Test data: (10000, 1024)\n",
      "Labeled samples: 40\n",
      "Unlabeled samples: 49960\n",
      "\n",
      "Applying PCA...\n",
      "Applying PCA to reduce dimensions to 60\n",
      "Data shape after PCA - Training: (50000, 60), Testing: (10000, 60)\n",
      "Data preprocessing completed.\n",
      "After PCA - Labeled: (40, 60), Unlabeled: (49960, 60)\n",
      "Number of classes: 10\n",
      "\n",
      "Initializing SGMM model...\n",
      "Training SGMM...\n",
      "------------------------------\n",
      "Starting training of Semi-Supervised GMM...\n",
      "Labeled samples: 40, Unlabeled samples: 49960\n",
      "Device: cuda\n",
      "  alpha shape: torch.Size([12])\n",
      "  mu shape: torch.Size([12, 60])\n",
      "  sigma shape: torch.Size([12, 60, 60])\n",
      "  beta shape: torch.Size([10, 12])\n",
      "Parameter initialization complete!\n",
      "Iteration 10 complete, Log-Likelihood: -3161255.4919\n",
      "Iteration 20 complete, Log-Likelihood: -3135741.4966\n",
      "Iteration 30 complete, Log-Likelihood: -3135655.6024\n",
      "\n",
      "Model converged at iteration 34\n",
      "Model training complete!\n",
      "Training completed in 0:00:16.152851\n",
      "\n",
      "Making predictions...\n",
      "\n",
      "Predicting 10000 samples...\n",
      "Prediction completed.\n",
      "\n",
      "============================================================\n",
      "EVALUATION ON TESTSET\n",
      "============================================================\n",
      "Test Accuracy: 0.9835\n",
      "Test Top-3 Accuracy: 0.9975\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Training Config\n",
    "training_config = {\n",
    "    'dataset': 'cifar10',\n",
    "    'feature_file': 'data/vit/cifar10/cifar10_vit_features.pt',\n",
    "    'labeled_per_class': 4,\n",
    "    'n_components_pca': 60,\n",
    "    'n_components_gmm': 12,\n",
    "    'tol': 1e0,\n",
    "    'max_iter': 1024,\n",
    "    'device': 'cuda',\n",
    "    'top_k': 3,\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "!python scripts/train_sgmm.py \\\n",
    "    --dataset {training_config['dataset']} \\\n",
    "    --feature_file {training_config['feature_file']} \\\n",
    "    --labeled_per_class {training_config['labeled_per_class']} \\\n",
    "    --n_components_pca {training_config['n_components_pca']} \\\n",
    "    --n_components_gmm {training_config['n_components_gmm']} \\\n",
    "    --tol {training_config['tol']} \\\n",
    "    --max_iter {training_config['max_iter']} \\\n",
    "    --device {training_config['device']} \\\n",
    "    --top_k {training_config['top_k']} \\\n",
    "    --seed {training_config['seed']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vitsgmm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
